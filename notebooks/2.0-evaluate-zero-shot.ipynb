{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Classification with Llama-2 7B and Llama-3 8B",
   "id": "5473bf7fe8463893"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "from transformers import LlamaForSequenceClassification, LlamaTokenizer, AutoTokenizer\n",
    "from datasets import load_dataset"
   ],
   "id": "df136ff72e9414ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load dataset and setup metrics",
   "id": "ddfd427ad2ee859f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_ds = load_dataset(\"aholovko/pep8_indentation_compliance\", split=\"validation\")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "task_evaluator = evaluate.evaluator(\"text-classification\")"
   ],
   "id": "d7941676129b1e48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-Shot Learning Llama 2",
   "id": "727ea843847c0cbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model2 = LlamaForSequenceClassification.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "tokenizer2 = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "task_evaluator.compute(\n",
    "    model_or_pipeline=model2,\n",
    "    tokenizer=tokenizer2,\n",
    "    data=val_ds,\n",
    "    input_column=\"code\",\n",
    "    label_column=\"label\",\n",
    "    metric=metric,\n",
    "    label_mapping={\"LABEL_0\": 0.0, \"LABEL_1\": 1.0},\n",
    ")"
   ],
   "id": "f914a2c096dd6be4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero-Shot Learning Llama 3",
   "id": "6a4fa4ee0bf49ca3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model3 = LlamaForSequenceClassification.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "task_evaluator.compute(\n",
    "    model_or_pipeline=model3,\n",
    "    tokenizer=tokenizer3,\n",
    "    data=val_ds,\n",
    "    input_column=\"code\",\n",
    "    label_column=\"label\",\n",
    "    metric=metric,\n",
    "    label_mapping={\"LABEL_0\": 0.0, \"LABEL_1\": 1.0},\n",
    ")\n"
   ],
   "id": "7f490a9c3b3d6f71",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
